from autogen_core import CancellationToken
from autogen_agentchat.base import Response
from autogen_agentchat.messages import BaseChatMessage, TextMessage
from autogen_agentchat.agents import BaseChatAgent  # Base class for custom agents
# Team classes and termination conditions
from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat
from autogen_agentchat.conditions import MaxMessageTermination
from typing import List
from schemas import AgentConfig
from autogen_core.tools import FunctionTool
from autogen_ext.models.openai import OpenAIChatCompletionClient
from agent_factory import create_agent_from_config  # centralized agent instantiation

class NestedTeamAgent(BaseChatAgent):
    """An agent that delegates to a nested team of sub-agents."""
    def __init__(self, agent_cfg: AgentConfig, all_tools: List[FunctionTool], default_model_client: OpenAIChatCompletionClient):
        """Build nested team agent from its config, tools, and default model client."""
        super().__init__(agent_cfg.name, description=agent_cfg.description or "Nested team agent")
        self.agent_cfg = agent_cfg
        self.all_tools = all_tools
        self.default_model_client = default_model_client
        # Initialize inner team
        self._init_team()

    def _init_team(self):
        # Instantiate sub-agents via centralized factory
        sub_agents = [
            create_agent_from_config(sub_cfg, self.all_tools, self.default_model_client)
            for sub_cfg in (self.agent_cfg.sub_agents or [])
        ]
        # Determine termination and mode
        term_cond = MaxMessageTermination(self.agent_cfg.max_consecutive_auto_reply or 5)
        mode = self.agent_cfg.mode or "round_robin"
        if mode == "selector":
            self._team = SelectorGroupChat(
                sub_agents,
                orchestrator_client=self.default_model_client,
                termination_condition=term_cond,
                selector_prompt=self.agent_cfg.orchestrator_prompt
            )
        else:
            self._team = RoundRobinGroupChat(sub_agents, termination_condition=term_cond)
        

    async def on_messages(
        self, messages: list[BaseChatMessage], cancellation_token: CancellationToken
    ) -> Response:
        # Run the inner team on the incoming messages (which include the new user prompt).
        result = await self._team.run(task=messages, cancellation_token=cancellation_token)
        # The inner team returns a TaskResult with a message history.
        all_msgs = result.messages
        final_msg = all_msgs[-1]  # team's final response message
        # Inner messages: those generated by sub-agents during this turn (exclude initial input and final output)
        inner_dialog = all_msgs[len(messages):-1] if len(all_msgs) > len(messages) else []
        return Response(chat_message=final_msg, inner_messages=inner_dialog)

    async def on_messages_stream(
        self, messages: list[BaseChatMessage], cancellation_token: CancellationToken
    ):
        # Stream inner team events (each BaseChatMessage or event from sub-agents) as they occur
        async for event in self._team.run_stream(task=messages, cancellation_token=cancellation_token):
            yield event

    async def on_reset(self, cancellation_token: CancellationToken) -> None:
        # Reset the inner team conversation state
        await self._team.reset()

    @property
    def produced_message_types(self):
        # Support text messages and any message types used by sub-agents (e.g., tool events, images if any).
        # At minimum, include TextMessage as the final output type.
        return (TextMessage,)

    # The old from_config is preserved for backward compatibility
    @classmethod
    def from_config(
        cls,
        agent_cfg: AgentConfig,
        all_tools: List[FunctionTool],
        default_model_client: OpenAIChatCompletionClient
    ) -> "NestedTeamAgent":
        return cls(agent_cfg, all_tools, default_model_client)
